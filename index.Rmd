---
title: "80's New Romantics vs 90's Trance: An Analytical Comparison"
author: "Joy Crosbie"
date: "Spring 2021"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: yeti
    orientation: rows
    vertical_layout: fill
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(spotifyr)
library(plotly)
library(kableExtra)
library(compmus)
library(patchwork)



get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  

eighties <- get_playlist_audio_features("", "7hIxxRmPxdpBa6zuDUC1FM")
trance <- get_playlist_audio_features("", "3XKJmcxhdP8NXIoamf5zwc")
```


```{r create playlists}
playlists <-
  bind_rows(
    eighties %>% mutate(playlist = "New Romantic"),
    trance %>% mutate(playlist = "Trance")
  )
```




### Introduction to the playlists: **New Romantics vs. Trance** {data-commentary-width=700}
My corpus consists of a playlist containing 80's New Romantic songs and a playlist containing trance classics from the early 90's to the mid 2010's. I was inspired by a statement made by BBC Radio 2, referring to Blue Monday (New Order's 1983 hit), as "a crucial link between Seventies disco and the dance/house boom that took off at the end of the New Romantic." The repetitive use of synths and heavy drum beats is a known characteristic of both New Romantic and trance music, and lead me to **compare the two and see what the main differences are between the two genres**. To do this, I will examine:

* Pitch features
* Timbre features
* Tempo
* Other variables from the Spotify API, such as danceability and valence.

Although the synthesizer is common in both playlists, there are some obvious differences when it comes to the tones. The 'punchy' synth sounds from the 80's have become more complex chord progressions of sweeping strings in trance music. I believe this will also be apparent in the valence and keys of the compared genres, because of the "poppy" influences of the new-romantic style compared to the euphoric feeling of trance music. I also believe that the tempo of the trance tracks will be spread across a smaller range of beats per minute (BPM). I am curious to see the difference in the 'energy' measured by Spotify, as I believe both genres contain a high amount of energy, but the energy they contain is different, as described above.

Typical examples of interesting tracks from the 80's playlist would be:

* Duel - Propaganda
* Fade To Grey - Visage. 

Both tracks contain a basic chord progression in a minor key played on a synthesizer repeated throughout the song, accompanied by a similar drum and high hat beat. 

Typical examples of interesting tracks from the trance playlist would be:

* Adagio for Strings - Tiësto
* Children - Robert Miles. 

Both songs contain well known riffs and are comprised of a musical form that distinctly builds tension to either end in "peaks" or "drops". Both songs are also in minor keys, a common characteristic of trance music.


***

<iframe src="https://open.spotify.com/embed/playlist/3XKJmcxhdP8NXIoamf5zwc" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/playlist/7hIxxRmPxdpBa6zuDUC1FM" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>



### Club Comeback: Which is **more danceable**, Trance or 80's New Romantics? {data-commentary-width=350}
```{r fig.width=12, fig.height=11}
dancetempo <- playlists %>%                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot(                     # Set up the plot.
    aes(
      x = tempo,
      y = danceability,
      name = track.name,
      color = playlist
    )
  ) +
  geom_point(show.legend = FALSE) +
  # Scatter plot.
  geom_rug(size = 0.1) +      # Add 'fringes' to show data distribution. 
  facet_wrap(~playlist) +     # Separate charts per playlist.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(105, 170),
    #breaks = c(0, 0.50, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0.3, 1),
    breaks = c(0.5, 0.75, 1),
    minor_breaks = NULL
  ) +
  scale_color_discrete(guide = 'none') +
  theme_light() +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "Tempo(BPM)",
    y = "Danceability"
  ) +
  ggtitle('Danceability: New Romantic vs. Trance') +
  theme(plot.title = element_text(hjust = 0.5))

dancetempo <- dancetempo + theme(legend.position = "none")

ggplotly(dancetempo)
```

***
*Hover over the track to see track information*

An immediate first observation is that the trance tracks range over a much smaller BPM interval.This was expected, as the genre is characterized by a tempo lying between 135-150 BPM. 

The majority of the tracks in both genres seem to lie between the 0.5-0.75 danceability interval. There are two key observations here:

Firstly, there are quite a few trance tracks with a 'low' danceability under 0.5. This is surprising to me, as trance is a form of dance music.


Moreover, as the tempo increases, the New Romantic tracks tend to become less danceable. 

### Trance: Not very danceable dance music? {data-commentary-width=350}

![Tempograms and novelty functions](\Users\jcros\Documents\Computational-Musicology\tgnvannotate.png)


*** 
As shown in the previous plot, quite a few of the trance tracks have been assigned a low danceability value. A common characteristic of trance music is a mid-song climax followed by a soft breakdown disposing of beats and percussion entirely, leaving the melody or atmospherics to stand alone for an extended period before gradually building up again. 

In [Sunrise (Radio-Edit) - Ratty](https://open.spotify.com/track/3dnGed4dwCkO2AoQVnbScw?si=F6ZgC9z6TbW757Am-VSEdw) these breakdown sections consist of a sample of female vocals from [Song to the Siren - This Mortal Coil](https://open.spotify.com/track/26uVYNtKahTAcZMDWiuBnt?si=zo7gV_09Su6Z1Y4q5olBlQ), with soft synths playing in the background. In these sections determining the tempo is difficult, as can be seen between 55 and 105 seconds and again after 200 seconds. 

When looking at the novelty function of the selected section, it becomes obvious that the lack of percussion in these sections causes Spotify to have trouble determining the note onsets, and the spurious peaks cause the 'random' tempo in the tempogram. This is presumably one of the reasons for the low danceability score (0.46), as danceable songs are presumed to have a relatively stable rhythm. Other trance tracks with a low danceability score such as [Communication](https://open.spotify.com/track/0W0tn4jpmnwnPZxO8nyhS7?si=i_NuEaQgTuWn4In4kTvNHQ) and [Shivers](https://open.spotify.com/track/0pfJH3eRkM4t9wlg6LwuTU?si=DoPEjtEMRTqm588RWUNMjQ) also contain acapella breakdowns.

A New Romantic track with the same danceability score is [I melt with you - Modern English](https://open.spotify.com/track/3xzRBn3ywzobJrc1efC7Sb?si=J3dkFQDFS9CQq23rJVPzmg). The New Romantic tracks typically stay at the same tempo throughout the song, but in this particular track the beat cuts out at 3.05 for just under 15 seconds and only the guitar is heard. Once again when we look at the novelty function, the lack of percussion causes spurious peaks. After less than 15 seconds, the beat resumes and the tempo becomes relatively stable again.

### Getting into the mood: Is trance music really happier than the 80's New Romantic music? {data-commentary-width=350}
```{r fig.width=12, fig.height=11}
scatter_feeling <- playlists %>%                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot(                     # Set up the plot.
    aes(
      x = valence,
      y = energy,
      size = loudness,
      colour = mode,
      name = track.name
    )
  ) +
  geom_point(alpha = 0.45, width = 0.1) +
   geom_rug(size = 0.1) +
  annotate("text", label = "Angry", x = 0.1, y = 0.55, size = 4, colour = "red")+
    annotate("text", label = "Happy", x = 0.6, y = 0.55, size = 4, colour = "purple")+
    annotate("text", label = "Sad", x = 0.1, y = 0.05, size = 4, colour = "blue")+
    annotate("text", label = "Calm", x = 0.6, y = 0.05, size = 4, colour = "green")+
  #geom_jitter(alpha = 0.45, width = 0.1) +
  facet_wrap(~ playlist) +
   scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1.0),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
   scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",              # Use an exp transformation to emphasize loud.
    guide = "none"            # Remove the legend for size.
  ) +
  theme_light() +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "Valence",
    y = "Energy",
    colour = "Mode"
  ) + ggtitle('Energy vs. Valence (size indicates loudness)') +
  theme(plot.title = element_text(hjust = 0.5))
ggplotly(scatter_feeling)
```

***
On the left an interactive (*Hover over the track to see track information*) plot of the energy and valence variables obtained from the Spotify API is shown. When combined, the four quadrants of the graph correspond to emotions. 

Both the New Romantic and the trance tracks mostly contain a high amount of energy. Surprisingly, the trance tracks generally emit a lower range of valence. High energy and low valence would indicate that trance music would be classified as angry. This is in contrast to the euphoric or slightly sad feeling the heavy synths are generally described to have. 

Mostly high energy and high valence means the New Romantic tracks would generally be perceived to be happy, though there are some in both the sad and angry region. 

The trace tracks are also louder than the New Romantic ones with an average overall loudness of -9.9dB compared to -8dB. This isn't too surprising, as dance music is generally quite loud.

Finally the trance playlist seems to contain slightly more tracks in a minor key. I had expected this, due to the fact that minor keys are a common occurrence in trance music.

### A (rare) 'euphoric' trance track: Peaks and vocals.{data-commentary-width=350}
```{r}
ernesto <-
  get_tidy_audio_analysis("0pMUR7Uvp6vxlbG0qBFvgM") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

ernesto %>%
  mutate(pitches = map(pitches, compmus_normalise, "manhattan")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Dark Side Of The Moon - Ernesto vs. Bastian") +
  theme_minimal() +
  scale_fill_viridis_c()
```

***
[Dark Side Of The Moon by Ernesto vs. Bastian](https://open.spotify.com/track/05lLA8ljMPozdEtFycI52o?si=_t7JeD6QQAK5jIO3w0vMsw) seems to stand out from the majority of 'angry' dance tracks and contains the highest valence in the trance dataset. Here the corresponding chromagram is shown. 

The song is a typical example of the structure of a trance track, as it is comprised of sections that distinctly build tension to either end in "peaks" or "drops". Here those sections can clearly be seen by the absence of the vocals which mostly make up B and C. 

The sequence on the synths (D#/E, F# and G#) repeats throughout the song and becomes louder when the vocals stop. At 120 sec there is a pure synth buildup to a 'peak' which ends around 150 seconds.

### Possible explanation for the angry trance tracks? - A comparison of musical keys for New Romantic and Trance tracks {data-commentary-width=350}
```{r}
playlists$key[playlists$key == "0"] <- "C"
playlists$key[playlists$key == "1"] <- "C#"
playlists$key[playlists$key == "2"] <- "D"
playlists$key[playlists$key == "3"] <- "D#"
playlists$key[playlists$key == "4"] <- "E"
playlists$key[playlists$key == "5"] <- "F"
playlists$key[playlists$key == "6"] <- "F#"
playlists$key[playlists$key == "7"] <- "G"
playlists$key[playlists$key == "8"] <- "G#"
playlists$key[playlists$key == "9"] <- "A"
playlists$key[playlists$key == "10"] <- "A#"
playlists$key[playlists$key == "11"] <- "B"

```

```{r}
ggplot(playlists, aes(x = key, fill = mode_name)) + 
  geom_bar() +
  facet_wrap(~playlist) +
  ggtitle('Keys of New Romantic and Trance tracks') +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

***

On the left a bar chart of the keys of the tracks for both genres is shown. The first clear observation is the large amount of New Romantic tracks in the key of C major. This key is commonly associated with pop music, so that isn't surprising. A typical example in this category would be [Just can't get enough by Depeche mode](https://open.spotify.com/track/0qi4b1l0eT3jpzeNHeFXDT?si=dbmWtCbgR2ejrj9GVcLTOg). 
Both A and A# also contain a relatively high amount of New Romantic tracks.


Another clear observation is the large amount of trance tracks in the key of G#, with this key being completely absent in the New Romantic playlist. Within music psychology this key is perceived to have a sense of death, eternity and judgment. At first the large amount of tracks seemed strange to me, but I believe this key gives off the haunting feeling that many trance tracks have. I read that this key could be described as "Expansive viewpoints of a dark cosmos and existence" and I feel this is indeed so. [Universal Nation by Push](https://open.spotify.com/track/34PgbZHudjUapNEqsb1WcW?si=xwvX8fEtQnOQtKywH00NRA) is a song in G# that really feels like a trip through the emptiness and eternity of space.

Moreover the trance playlist seems to contain a relatively high number of songs in G. This key is perceived to contain a feeling of fantasy and peace, which is more what I expected to find.

The trance playlist also contains songs in C#, while this key is absent from the New Romantic playlist. The proportion of minor keys seems to indeed be higher in the trance playlist.



### Chroma and timbre in 80's New Romantic pop: A typical example {data-commentary-width=350}

```{r fig.width = 7}
duel <-
  get_tidy_audio_analysis("4M2tEAdFRdg0U8rAgYa8o2") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"
      )
  )
bind_rows(
  duel %>%
    compmus_self_similarity(pitches, "manhattan") %>%
    mutate(d = d / max(d), type = "Chroma"),
  duel %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "") +
  ggtitle('Comparison of timbre and chroma features: Duel - Propaganda') +
  theme(plot.title = element_text(hjust = 0.5))
```

*** 
[Duel by Propaganda](https://open.spotify.com/track/4M2tEAdFRdg0U8rAgYa8o2?si=NqMAbydvRBK9_zgHDP6v1w) is a typical example of an 80's New Romantic track. The track contains two basic synth chord progressions: one that is repeated throughout the verses and one for the chorus. During the pre-chorus a single chord is played. These repetitive sections can clearly be seen in the chroma plot, with the first verse lasting from 10-47 seconds, followed by the pre-chorus from 47-60 seconds and then the chorus from 60-90 seconds. The second chorus is followed by an instrumental bridge as can be seen by the distinctive section ranging from 160-200 seconds. The chorus is then repeated until the end of the song.

An important observation with this track is that the chroma plot and the timbre plot seem to show the same similarity pattern. This is because Both plots show the distinctive sections and their repetitions, as there is no variation between the different verses. The bridge is particularly interesting here, as the timbre is different to the other sections of the song. The song suddenly slows down and the melody changes for about ten seconds, to then instrumentally build up to the chorus. 

### Chroma and timbre in 90's trance: A typical example {data-commentary-width=350}

```{r fig.width = 7}
children <-
  get_tidy_audio_analysis("73iNrs3ww2JCPHS4pgTryg") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  children %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  children %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")  +
  ggtitle('Comparison of timbre and chroma features: Children - Robert Miles') +
  theme(plot.title = element_text(hjust = 0.5))
```

***
[Children by Robert Miles](https://open.spotify.com/track/73iNrs3ww2JCPHS4pgTryg?si=hz1Mn-qtRpKItDDrNY-tIQ) is a well known trance classic from 1995. Many are familiar with its dream-like melodies and steady four-on-the-flour bass drum. Miles was inspired both by a response to photographs of child Yugoslav war victims that his father had brought home from a humanitarian mission and his idea to create a track to end DJ sets, intended to calm rave attendants prior to their driving home as a means to reduce car accident deaths. 

The chroma plot shows the repetition of two main sections, with the checkerboard pattern from 45-95 seconds being the chorus with the well known dreamy synth melody. The section from 95-135 seconds contains a heavy beat with shorter staccato synth melodies.

The timbre plot is interesting, as it shows a general trend in the trance tracks where the timbre doesn't correspond to the clear checkerboard pattern shown in the chroma plot. This is quite strange, as one would suspect the simple structure of the song should be reflected here too. When listening closely, the second chorus feels slightly 'busier' than the first chorus, which leads me to believe there are more layers of instruments playing the same notes in the second repetition. This would explain why you couldn't detect this change in the chroma plot. At 190 seconds the timbre of the song is very different from other sections, as can be seen by the bright cross. In this section the melodies pick up in speed and become more urgent than dreamy. 



### Classification {data-commentary-width=350}

![Classification](\Users\jcros\Downloads\classification.png)

***
In this section I compare various classifiers to distinguish between the trance and New Romantic playlist. In each case 10-fold cross validation was applied.


The first classifier I tried when trying to distinguish between the trance and New Romantic tracks was a random forest classifier. This classifier already performs well. The results are shown in the following table.

class        | precision    | recall
-------------| -------------|-------------
New Romantic | 0.9066667	  |0.9066667
Trance       | 0.9320388	  |0.9320388

Using a random-forest classifier, the most important features for classifying tracks among these playlists are (ranked from most to least important):

1. Timbre Component 6
2. Valence
3. Timbre Component 3
4. Tempo
5. Instrumentalness

After these five features, there is a substantial drop in importance. The results of the random forest classifier with just these five features are shown below:

class        | precision    | recall
-------------| -------------|-------------
New Romantic | 0.9342105	  |0.9466667
Trance       | 0.9607843	  |0.9514563


The classifier achieves a higher precision and recall for both genres when only the top 5 most important features are used.

When plotting two of the most important features, a non linear decision boundary can be observed as shown in the plot on the left. This lead me to try a Support Vector Machine (SVM), in the hopes to be able to capture the corresponding decision regions. The SVM results are shown below using all features:

class        | precision    | recall
-------------| -------------|-------------
New Romantic | 0.9605263	  |0.9733333
Trance       | 0.9803922	  |0.9708738




Both the precision and recall go up by an extra 2%. The confusion matrix is shown on the left. The the SVM does a very good job at distinguishing between the two.



### Conclusion

In this portfolio I analyzed a trance and New Romantic playlist in order to find the main differences between the two genres. I had expected to find differences in valence, key, tempo and energy. To do this I examined Pitch, Timbre, tempo and other variables from the Spotify API. I will discuss my main findings below:

* Tempo

My tempo findings confirmed my initial suspicions, the trance tracks are indeed mostly spread over a range of 135-150 BPM. I also found that New Romantic tracks become less danceable after abut 130 BPM onwards.

* Pitch Features

My main pitch finding was that the distribution of musical keys looks different for each genre. The trance playlist contained a lot of tracks in the keys of G and G#, while the New Romantic playlist contained none. The New Romantic playlist did contain a lot of tracks in the key of C compared to the trance playlist. I was very surprised to find that a lot of the trance tracks were classified as angry. I wonder whether one of the factors Spotify looks at could be key information, as the relatively large amount of tracks contained in G# were said to have a sense of death from a music psychology perspective. When this is combined with the high energy values that the trance tracks contained, I could see how that could point in the direction of an angry classification.

* Timbre Features

Interestingly, while the chroma plots often seemed to correspond to the timbre plots for the New Romantic playlist, this often wasn't the case for the trance tracks. While analyzing this further I learned about how the structures of pop songs differ from trance tracks. A typical pop song may consist of the following structure “Intro – Verse – Pre-Chorus – Chorus – Verse – Pre-Chorus – Chorus – Outro”, while the most common track structure for trance is : “Intro – Buildup – Breakdown – Build – Climax – Outro”. While pop songs generally maintain the same harmonies throughout the song, trance track sections can vary slightly in order to take the listener on a journey. This often means they will vary the levels of energy thoughout the song, which could lead to a difference in timbre.

WHO COULD THIS BENEFIT???